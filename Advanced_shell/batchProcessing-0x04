command ping -i 5 google.com &
Output
[1] 4287

output
PING google.com (74.125.226.71) 56(84) bytes of data.
64 bytes from lga15s44-in-f7.1e100.net (74.125.226.71): icmp_seq=1 ttl=55 time=12.3 ms
64 bytes from lga15s44-in-f7.1e100.net (74.125.226.71): icmp_seq=2 ttl=55 time=11.1 ms
64 bytes from lga15s44-in-f7.1e100.net (74.125.226.71): icmp_seq=3 ttl=55 time=9.98 ms

jobs
Output
[1]+  Running                 command ping -i 5 google.com &

kill %1

Output
[1]+  Terminated              command ping -i 5 google.com

bg
Output
[1]+ ping -i 5 google.com &

fg
fg %2

nohup ping -i 5 google.com &

Output
nohup: ignoring input and appending output to ‘nohup.out’

pgrep -a ping
Output
7360 ping -i 5 google.com

kill 7360
disown %2
disown -h %1

shopt huponexit
shopt -s huponexit
exit

#!/bin/bash

# Configuration
API_URL="https://pokeapi.co/api/v2/pokemon/"
POKEMON_LIST=("bulbasaur" "ivysaur" "venusaur" "charmander" "charmeleon")
OUTPUT_DIR="pokemon_data" # Directory to store individual JSON files
LOG_FILE="parallel_fetch.log"

# Setup: Create output directory and clear log file
mkdir -p "$OUTPUT_DIR"
> "$LOG_FILE"
echo "Starting parallel data fetch for ${#POKEMON_LIST[@]} Pokémon..." | tee -a "$LOG_FILE"

# Function to fetch data for a single Pokémon
# This function is run as a separate background process for each Pokémon.
fetch_single_pokemon() {
    local pokemon_name=$1
    local output_file="$OUTPUT_DIR/${pokemon_name}.json"
    
    # Use curl to fetch the data
    # -s: Silent mode
    # -o: Output to the specified file
    # -f: Fail silently on HTTP errors (like 404), ensuring curl returns a non-zero exit code
    
    # We redirect stdout/stderr to the main log file to prevent output interleaving
    curl -s -f -o "$output_file" "${API_URL}${pokemon_name}" 2>&1 1>>"$LOG_FILE"

    local exit_status=$?

    if [ $exit_status -eq 0 ]; then
        echo "[SUCCESS] $(date +%T): Fetched $pokemon_name and saved to $output_file" >> "$LOG_FILE"
    else
        # This catches network errors OR HTTP errors like 404 (due to the -f flag)
        echo "[ERROR] $(date +%T): Failed to fetch $pokemon_name. Curl exit status: $exit_status" >> "$LOG_FILE"
        # Clean up the file if the curl failed
        rm -f "$output_file"
    fi
}

# --- Parallel Execution ---

# Loop through the list and launch each function call into the background
for poke in "${POKEMON_LIST[@]}"; do
    fetch_single_pokemon "$poke" & # The ampersand (&) sends the job to the background
    echo "Launched background job for $poke. PID: $!" >> "$LOG_FILE"
done

# --- Process Management ---
# Wait for all background jobs to complete
echo "Waiting for all parallel jobs to finish..." | tee -a "$LOG_FILE"
wait # The 'wait' command blocks the script until all background processes started in the current shell finish.

echo "---------------------------------------------------------" | tee -a "$LOG_FILE"
echo "All parallel data fetches are complete. Results in $OUTPUT_DIR/." | tee -a "$LOG_FILE"
echo "Summary of operations in $LOG_FILE"
